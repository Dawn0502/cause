# Snakemake pipeline for running CAUSE on pairs of GWAS traits
#
# This snakefile performs the following steps for each pair of traits:
# * Format data
# * Merge data
# * Obtain LD pruned set of variants ascertaining on trait M p-value
# * Run CAUSE
# * Run other MR methods if desired
#
# LICENSE: CC0. Do what you want with the code, but it has no guarantees.
#          https://creativecommons.org/share-your-work/public-domain/cc0/
#
# Installation with conda package manager:
#
# conda create -n cause_large python=3.6  pandas snakemake
# source activate cause_large


#To run the full pipeline, submit the following line from within the
#same directory as the Snakefile while on the head node (the paths to
#        the data files are relative to the Snakefile):
# nohup ./run-snakemake.sh &
#


import pandas as pd
from snakemake.utils import validate

localrules: all

###### Load configuration file
configfile: "config.yaml"
# validate(config, schema="schemas/config.schema.yaml")
ss = pd.read_csv(config["input"]["sum_stats"], na_filter=False)

gwas_data_dir = config["out"]["gwas_data_dir"] #where formatted gwas data go
data_dir = config["out"]["other_data_dir"] #where other data go

out_dir = config["out"]["output_dir"] #where CAUSE results will go

if config["analysis"]["all_pairs"]:
   names1 = ss["name"]
   names2 = ss["name"]
else:
    names1 = [ss["name"][int(i)-1] for  i in str(config["analysis"]["trait1"]).split(",")]
    names2 = [ss["name"][int(i)-1] for  i in str(config["analysis"]["trait2"]).split(",")]

trait_pairs = [(n1, n2) for n1 in names1 for n2 in names2 if n1!=n2]

rule all:
    input: expand(out_dir + "df_{method}.RDS", method=config["analysis"]["methods"])

# Format data
rule format:
    input: raw_data  = lambda wildcards: ss[ss['name'] == wildcards.name]['raw_data_path'].tolist()[0]
    output: formatted_data = gwas_data_dir + '{name}_summary_statistics.tsv.gz'
    params:
        delim = lambda wildcards: ss[ss['name'] == wildcards.name]['delimeter'].tolist()[0],
        snp = lambda wildcards: ss[ss['name'] == wildcards.name]['snp'].tolist()[0],
        A1 = lambda wildcards: ss[ss['name'] == wildcards.name]['A1'].tolist()[0],
        A2 = lambda wildcards: ss[ss['name'] == wildcards.name]['A2'].tolist()[0],
        beta_hat = lambda wildcards: ss[ss['name'] == wildcards.name]['beta_hat'].tolist()[0],
        se = lambda wildcards: ss[ss['name'] == wildcards.name]['se'].tolist()[0],
        p_value = lambda wildcards: ss[ss['name'] == wildcards.name]['p_value'].tolist()[0],
        sample_size = lambda wildcards: ss[ss['name'] == wildcards.name]['sample_size'].tolist()[0]
    shell: "Rscript R/format_data.R {input.raw_data} {params.delim} {params.snp} {params.A1} {params.A2} {params.beta_hat} {params.se} {params.p_value}  {params.sample_size} {output.formatted_data}"


# These two steps are the same. We do it twice so that if we re-run we don't have to redo the LD pruning
# The alternative would be to not make these temp files but storing copies of this data is a bit excessive
rule data_merge1:
    input: file1 = gwas_data_dir + '{n1}_summary_statistics.tsv.gz',
           file2 = gwas_data_dir + '{n2}_summary_statistics.tsv.gz'
    output: out= temp(data_dir + "{n1}__{n2}_data1.RDS")
    shell: "Rscript R/merge_data.R {input.file1} {input.file2} {output.out} "

rule data_merge:
    input: file1 = gwas_data_dir + '{n1}_summary_statistics.tsv.gz',
           file2 = gwas_data_dir + '{n2}_summary_statistics.tsv.gz'
    output: out= temp(data_dir + "{n1}__{n2}_data.RDS")
    shell: "Rscript R/merge_data.R {input.file1} {input.file2} {output.out} "


## LD pruning

## Built in cause method (slow)
rule ld_prune_one_chrom:
    input: data = data_dir + '{tag1}__{tag2}_data1.RDS',
           r2 = config["ld"]["cause_opts"]["ld_dir"] + 'chr{chrom}' + config["ld"]["cause_opts"]["r2_file"],
           info =  config["ld"]["cause_opts"]["ld_dir"] + 'chr{chrom}' + config["ld"]["cause_opts"]["info_file"]
    output: out=temp(data_dir + "snps_{tag1}__{tag2}.cause.pruned.{chrom}.RDS")
    shell:   'Rscript R/ld_prune_one_chrom.R {input.data} \
                   {config[analysis][cause_pval]} {config[ld][r2_thresh]} {input.r2} \
                   {input.info} {output.out}'

rule ld_prune_combine:
    input: files = expand( data_dir + "snps_{{tag1}}__{{tag2}}.cause.pruned.{chr}.RDS", chr = range(1, 23))
    output: out = data_dir + "snps_{tag1}__{tag2}.cause.pruned.txt"
    shell: "Rscript R/ld_cat.R {output.out} {input.files}"

## Plink method (fast)
rule ld_prune_plink:
    input: data = data_dir + '{tag1}__{tag2}_data1.RDS',
           ref_data = expand(config["ld"]["plink_opts"]["ref_path"] + '.{end}', end  = ["bim", "bed", "fam"])
    output: out = data_dir + "snps_{tag1}__{tag2}.plink.pruned.txt"
    shell:   'Rscript R/ld_prune_one_chrom.R {input.data} \
                   {config[analysis][cause_pval]} {config[ld][r2_thresh]} \
                   {config[ld][plink_opts][ref_path]}  {output.out}'


#Run CAUSE
rule cause_params:
    input: data = data_dir + '{tag1}__{tag2}_data.RDS',
    output: params = out_dir + '{tag1}__{tag2}_params.RDS',
    shell: 'Rscript R/cause_params.R {input.data} {output.params} {config[analysis][cause_seed]}'

lm = config["ld"]["ld_prune_method"]
rule cause:
    input: data = data_dir + '{tag1}__{tag2}_data.RDS',
           snps = data_dir + 'snps_{tag1}__{tag2}.' + lm + '.pruned.txt',
           params = out_dir + '{tag1}__{tag2}_params.RDS'
    output: cause = out_dir + '{tag1}__{tag2}_cause_{qa}_{qb}.RDS'
    params: maxq = 1
    shell: 'Rscript R/cause.R {input.data} {input.snps} {input.params} \
                   {wildcards.qa} {wildcards.qb} {params.maxq} \
                   {output.cause} {config[analysis][cause_seed]}'


## Other MR
mr_pval = config["analysis"]["mr_pval"]
rule mrpresso:
    input: data = data_dir + '{tag1}__{tag2}_data.RDS',
           snps = data_dir + 'snps_{tag1}__{tag2}.' + lm + '.pruned.txt'
    output: out = out_dir + '{tag1}__{tag2}_mrpresso.RDS',
    params: mr_pval =  mr_pval
    shell: 'Rscript R/mrpresso.R {input.data} {input.snps} {params.mr_pval} {output.out} '

rule lcv:
    input: data = data_dir + '{tag1}__{tag2}_data.RDS',
    output: out = out_dir + '{tag1}__{tag2}_lcv.RDS'
    params: ld_score_dir = config["ld"]["ld_score_dir"]
    shell: 'Rscript R/lcv.R {input.data}  {params.ld_score_dir} {output.out}'

rule mr_package:
    input: data = data_dir + '{tag1}__{tag2}_data.RDS',
           file1 = gwas_data_dir + '{tag1}_summary_statistics.tsv.gz',
           snps = data_dir + 'snps_{tag1}__{tag2}.' + lm + '.pruned.txt'
    params: mr_pval =  mr_pval
    output: out = out_dir + '{tag1}__{tag2}_mrpackage.RDS',
    shell: 'Rscript R/mr_package.R {input.data} {input.file1} {input.snps} {params.mr_pval} {output.out} '


rule summary:
    input:  expand(out_dir + '{tp[0]}__{tp[1]}_{{method}}.RDS', tp = trait_pairs)
    output: out_dir + "df_{method}.RDS"
    params: outdir = out_dir
    shell: "Rscript R/extract_results.R {params.outdir} {wildcards.method}"

